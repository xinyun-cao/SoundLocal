{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccff4c26-fed8-497a-9eae-2ea6c18b819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "788c7494-c53b-4771-b296-98543c14ba4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up if using dnn\n",
    "# prototxtPath = r\"face_detector/deploy.prototxt\"\n",
    "# weightsPath = r\"face_detector/res10_300x300_ssd_iter_140000_fp16.caffemodel\"\n",
    "# net = cv2.dnn.readNetFromCaffe(prototxtPath, weightsPath)\n",
    "PREDICTOR_PATH = r\"face_detector/shape_predictor_68_face_landmarks.dat\"\n",
    "LIP_DIST_CUTOFF = 5.0\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'XVID') \n",
    "# out = cv2.VideoWriter('output.avi', fourcc, 20.0, (640, 480)) \n",
    "\n",
    "predictor = dlib.shape_predictor(PREDICTOR_PATH)\n",
    "while True:\n",
    "    success, image = cap.read()\n",
    "    h, w = image.shape[:2]\n",
    "    \n",
    "    # detector usage if using dnn\n",
    "    # blob = cv2.dnn.blobFromImage(cv2.resize(img, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "    # net.setInput(blob)\n",
    "    # detections = net.forward()\n",
    "    \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray)\n",
    "\n",
    "    # draw bounding box\n",
    "    for face in faces:\n",
    "        x, y, w, h = (face.left(), face.top(), face.width(), face.height())\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        dlib_rect = dlib.rectangle(int(x), int(y), int(x + w), int(y + h))\n",
    "        landmarks = np.matrix([[p.x, p.y]  \n",
    "               for p in predictor(image, dlib_rect).parts()])\n",
    "        mouth_point_up = landmarks[62]\n",
    "        mouth_point_down = landmarks[66]\n",
    "        # print out landmark for upper lip and lower lip\n",
    "        counter = 0\n",
    "        for point in (mouth_point_up, mouth_point_down):  \n",
    "            pos = (point[0, 0], point[0, 1])\n",
    "            cv2.circle(image, pos, 2, color=(0, 255, 255), thickness=-1)\n",
    "            counter+= 1\n",
    "        dist = np.linalg.norm(mouth_point_up-mouth_point_down)\n",
    "        if dist > LIP_DIST_CUTOFF:\n",
    "            cv2.putText(image, \"speaking!\", (x, y - 10),  \n",
    "               fontFace=cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,  \n",
    "               fontScale=1,  \n",
    "               color=(0, 0, 255))\n",
    "\n",
    "    # bounding box detection if using dnn\n",
    "    # for i in range(detections.shape[2]):\n",
    "    #     confidence = detections[0, 0, i, 2]\n",
    "    #     if confidence > 0.5:\n",
    "    #         x1 = int(detections[0, 0, i, 3] * w)\n",
    "    #         y1 = int(detections[0, 0, i, 4] * h)\n",
    "    #         x2 = int(detections[0, 0, i, 5] * w)\n",
    "    #         y2 = int(detections[0, 0, i, 6] * h)\n",
    "    #         cv2.rectangle(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "\n",
    "    cv2.imshow(\"Webcam\", image) # This will open an independent window\n",
    "    out.write(image)\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'): # quit when 'q' is pressed\n",
    "        cap.release()\n",
    "        break\n",
    "\n",
    "# out.release()  \n",
    "cv2.destroyAllWindows() \n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1f4f9d-950a-4732-9f3e-d1b58a109849",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
